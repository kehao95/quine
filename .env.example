# Quine Configuration
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# Then source it before running quine:
#   source .env && quine "Hello"
#
# IMPORTANT: Every line must start with 'export' so that
# 'source .env' exports variables to child processes.

# ── Required ──────────────────────────────────────────────
# Model name sent to the API (e.g. claude-sonnet-4-5-20250929, gpt-4o)
export QUINE_MODEL_ID=claude-sonnet-4-5-20250929

# ── Auto-detected for known models ───────────────────────
# For claude-*, gpt-*, o1-*, o3-*, o4-* models, the following
# three variables are auto-detected. Set them explicitly for
# third-party providers (Moonshot, Together, Ollama, vLLM, etc.)

# Wire protocol: "openai" or "anthropic"
# export QUINE_API_TYPE=openai

# API base URL
# export QUINE_API_BASE=https://api.openai.com

# API key (falls back to OPENAI_API_KEY or ANTHROPIC_API_KEY)
# export QUINE_API_KEY=sk-...

# ── Provider API keys (used as fallback) ─────────────────
# export OPENAI_API_KEY=sk-...
# export ANTHROPIC_API_KEY=sk-ant-...

# ── Optional ─────────────────────────────────────────────
# export QUINE_MAX_DEPTH=5            # Max recursion depth
# export QUINE_MAX_TURNS=20           # Max conversation turns (0 = unlimited)
# export QUINE_CONTEXT_WINDOW=200000  # Context window size in tokens
# export QUINE_DATA_DIR=.quine/       # Session log directory
# export QUINE_SH_TIMEOUT=600         # Shell command timeout (seconds)
# export QUINE_MAX_CONCURRENT=20      # Max concurrent child processes
