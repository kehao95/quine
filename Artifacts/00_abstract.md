# Abstract

Current autonomous agent architectures are constrained by a pervasive anthropomorphic bias, organizing Large Language Models (LLMs) into "sociological" simulacra of human collaboration—chatrooms, roles, and consensus-seeking dialogues. We argue that this paradigm introduces irreducible stochasticity, context pollution, and scaling failures. In this work, we propose **Quine**, a recursive cognitive architecture that rejects biological metaphors in favor of a strict ontological mapping to POSIX primitives.

By redefining the Agent as an ephemeral Operating System Process, Quine establishes a fractal isomorphism between the laws of computing and the dynamics of cognition. In this framework, **Context** is reified as Volatile RAM (a high-entropy buffer), while **State** is strictly persisted to the Filesystem. "Reasoning" emerges as a Process Tree (recursive decomposition), and **Error Signals** are strictly typed as Standard Error streams (`stderr`). Crucially, we treat these streams not as logs, but as **Semantic Gradients** ($\hat{\nabla} L$) for optimization, enabling parent processes to modify the prompts of child processes in runtime—effectively performing **In-Context Gradient Descent**. This separation establishes a cognitive **Harvard Architecture**, enforcing a strict structural boundary between the agent's **Mission** (immutable `argv`) and its **Data Stream** (mutable `stdin`).
 By treating the mission as Read-Only Code and the context as Volatile Memory, the architecture mitigates prompt injection vectors not through heuristic filtering, but through fundamental lifecycle management. Furthermore, we model reasoning as a thermodynamic process: as context entropy accumulates, agents must undergo "cognitive metabolism"—using `fork` for parallel exploration and `exec` for self-purification—to maintain coherence. This transforms the problem of agentic control from one of Prompt Engineering (soft, linguistic constraints) to one of **Computational Physics** (hard, kernel-enforced constraints). We demonstrate that by subjecting agents to the thermodynamic pressures of the OS environment—resource scarcity, process isolation, and input/output purity—robust, self-correcting behaviors emerge not via design, but via evolutionary selection. Additionally, we present experimental results demonstrating **Scale-Invariant Retrieval**, showing that recursive process reincarnation (`exec`) effectively decouples cognitive performance from context window limitations.
